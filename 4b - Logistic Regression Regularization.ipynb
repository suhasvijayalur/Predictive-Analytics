{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This script illustrates the effects of regularization for Logistic Regression. \n",
    "\n",
    "%matplotlib inline\n",
    "# import necessary libraries and specify that graphs should be plotted inline. \n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the data set\n",
    "# See '2 - Decision Trees' for a description of this data set\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Pre-process the data set\n",
    "\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance.\n",
    "X = StandardScaler().fit_transform(X)\n",
    "# Centering and scaling happen independently on each feature by computing the relevant statistics on the samples\n",
    "# in the training set. Mean and standard deviation are then stored to be used on later data using the transform\n",
    "# method.\n",
    "# Standardization of a dataset is a common requirement for many machine learning estimators: they might behave\n",
    "# badly if the individual feature do not more or less look like standard normally distributed data (e.g. Gaussian\n",
    "# with 0 mean and unit variance).\n",
    "# For instance many elements used in the objective function of a learning algorithm (such as the RBF kernel of\n",
    "# Support Vector Machines or the L1 and L2 regularizers of linear models) assume that all features are centered\n",
    "# around 0 and have variance in the same order. If a feature has a variance that is orders of magnitude larger\n",
    "# that others, it might dominate the objective function and make the estimator unable to learn from other features\n",
    "# correctly as expected.\n",
    "\n",
    "# classify small against large digits (i.e., convert the task from multi-class classification to binary classification)\n",
    "y = (y > 4).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=100.00\n",
      "Sparsity with L1 penalty: 6.25%\n",
      "score with L1 penalty: 0.9098\n",
      "Sparsity with L2 penalty: 4.69%\n",
      "score with L2 penalty: 0.9098\n",
      "C=1.00\n",
      "Sparsity with L1 penalty: 10.94%\n",
      "score with L1 penalty: 0.9098\n",
      "Sparsity with L2 penalty: 4.69%\n",
      "score with L2 penalty: 0.9093\n",
      "C=0.01\n",
      "Sparsity with L1 penalty: 85.94%\n",
      "score with L1 penalty: 0.8637\n",
      "Sparsity with L2 penalty: 4.69%\n",
      "score with L2 penalty: 0.8915\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x371d5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set regularization parameter\n",
    "for i, C in enumerate((100, 1, 0.01)):\n",
    "    # we create an instance of the Classifier\n",
    "    # turn down tolerance for short training time\n",
    "    clf_l1_LR = linear_model.LogisticRegression(C=C, penalty='l1', tol=0.01)\n",
    "    clf_l2_LR = linear_model.LogisticRegression(C=C, penalty='l2', tol=0.01)\n",
    "    # Train the model (fit the data)    \n",
    "    clf_l1_LR.fit(X, y)\n",
    "    clf_l2_LR.fit(X, y)\n",
    "\n",
    "    # Get the coefficients of the models\n",
    "    coef_l1_LR = clf_l1_LR.coef_.ravel()\n",
    "    coef_l2_LR = clf_l2_LR.coef_.ravel()\n",
    "\n",
    "    # coef_l1_LR contains zeros due to the L1 sparsity inducing norm\n",
    "    sparsity_l1_LR = np.mean(coef_l1_LR == 0) * 100\n",
    "    sparsity_l2_LR = np.mean(coef_l2_LR == 0) * 100\n",
    "\n",
    "    print(\"C=%.2f\" % C)\n",
    "    print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity_l1_LR)\n",
    "    print(\"score with L1 penalty: %.4f\" % clf_l1_LR.score(X, y))\n",
    "    print(\"Sparsity with L2 penalty: %.2f%%\" % sparsity_l2_LR)\n",
    "    print(\"score with L2 penalty: %.4f\" % clf_l2_LR.score(X, y))\n",
    "    # score() returns the mean accuracy on the given test data and labels.\n",
    "    \n",
    "    l1_plot = plt.subplot(3, 2, 2 * i + 1)\n",
    "    l2_plot = plt.subplot(3, 2, 2 * (i + 1))\n",
    "    if i == 0:\n",
    "        l1_plot.set_title(\"L1 penalty\")\n",
    "        l2_plot.set_title(\"L2 penalty\")\n",
    "\n",
    "    l1_plot.imshow(np.abs(coef_l1_LR.reshape(8, 8)), interpolation='nearest',\n",
    "                   cmap='binary', vmax=1, vmin=0)\n",
    "    l2_plot.imshow(np.abs(coef_l2_LR.reshape(8, 8)), interpolation='nearest',\n",
    "                   cmap='binary', vmax=1, vmin=0)\n",
    "    plt.text(-8, 3, \"C = %.2f\" % C)\n",
    "\n",
    "    l1_plot.set_xticks(())\n",
    "    l1_plot.set_yticks(())\n",
    "    l2_plot.set_xticks(())\n",
    "    l2_plot.set_yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What differences do you observe between L1 and L2 regularization?\n",
    "\n",
    "# The C parameter controls the amount of regularization in the LogisticRegression object: a large value\n",
    "# for C results in less regularization. penalty=\"l2\" gives Shrinkage (i.e. non-sparse coefficients), while\n",
    "# penalty=\"l1\" gives Sparsity."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
